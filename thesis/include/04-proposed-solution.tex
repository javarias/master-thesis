\chapter{Proposed Solution} 

As stated in section~\ref{sec:problems} two problems were identified, these both problems are part of the ALMA Observation scheduling problem.
This part of the work describes the proposed solution for both problems, which are related between each other.
The solution is modeled after ALMA requirements and current software design detailed in~\cite{avarias11,clarke12,schwarz04,apdm-model} and aims to solve the whole ALMA Observation scheduling problem. Although some simplifications are considered, mainly because either there are still certain requirements that are under discussion or they are still unclear. 

As stated in section~\ref{sec:alma-sched-problem}, each array is handled independently by the scheduling subsystem software, this means that each array will have its own scheduler instance, and they are considered a different instrument during them life. At very same time one or more arrays can be running, hence the multiple schedulers instances can be active, and the data containing the Observation Projects and Scheduling Blocks is common to all the schedulers.

Even though is possible to have linked Scheduling Blocks between each other as prerequisites, the solution proposed here will not considered here due they are not well defined in the ALMA software requirements and they are still in discussion. This implies that the Scheduling Blocks belonging to an Observation Project can be observed and completed in any order.

Instrument calibrations and pointing calibration is a very important step before the actual usage of the instrument, increasing the accuracy and sensitivity of the instruments. However for now, the algorithm will consider that the telescope is always calibrated and ready to observe. Also observation session management will not be considered at all due calibrations dependencies.

The time period to schedule observations could not be continuous, this means that there may be time periods during the day where the instruments will not function to produce science. Since this is planned, the time not used for science is not considered as downtime. Dynamic or random downtimes have been not considered and they are out of the scope of the problem presented in this work.

The time spent in a single execution (observing) is variable, it depends completely on the Scheduling Block to be observed. Usually the requested duration goes from 30 minutes until 3 hours. The Observation project and Scheduling Blocks will be considered completely observed according to the rules discussed in section~\ref{subsec:completing-obs} 

The current ALMA DSA does the search based on the Local Sidereal Time (LST). The algorithm(s) proposed must use LST are main time unit to schedule observations.

The arrays configurations are given as input to the algorithm, the algorithm will try to accommodate over the observing season the given configurations. It is not responsibility of the algorithm to come up with suggestions related to changes in the configurations.
 
\section{ALMA's Astronomical observation scheduling problem}
\label{sec:astro-schedule-problem}
This problem only considers the execution of Scheduling Block inside the same Array Configuration. The algorithm lifecycle is tied to the current ALMA requirements shown in section~\ref{sec:alma-sched-problem} figure~\ref{fig:sched-dsa-state-machine}, which is detailed as follows:

\begin{description}
\item[Run static parameter's selector] \hfill \\
After running these selectors the algorithm will return a list of the potential candidates given current static conditions, this includes the visibility for the representative target which is known beforehand, but is not filterable until the algorithm knows the current Local Sidereal Time. If after this state there is no feasible solution, then the algorithm will return nothing.

\item[Update dynamic parameters] \hfill \\
In this state the algorithm will recalculate the parameters requiring update at the given time. Usually weather conditions and parameters that cannot be calculated beforehand (e.g. altitude of a source for the given time, the point in the sky is in RA-Dec coordinates).  

\item[Run dynamic parameter's selector] \hfill \\
This will filter out all the Scheduling Blocks which do not fit in the criteria established after the dynamic updates ran. As the first state it will return a list of the candidate SB. If after this state there is no feasible solution, then the algorithm will return nothing.

\item[Rank all candidate Scheduling Blocks] \hfill \\
The algorithm might have a list of scorers, each one of these ``scorers'' will assign a value between ${[ 0 , 1 ]}$. The algorithm also will have a list of weights, one per scorer. The final result of each Scheduling Blocks will be sum of all the weighted scores given to this Scheduling Block for the given time to the algorithm.

\item[Select best ranked Scheduling Block] \hfill \\
The algorithm will select, and will return, the ``best'' suitable Scheduling Blocks for the given time.

\end{description}

\subsection{Mathematical model}
\label{sec:array-sched-math-model}
A generic representation of the model is presented in figure~\ref{fig:obs-schedule-representation}. The model considers only one array configuration, its life is represented by the horizontal arrow at top of the figure. On this time the proposed algorithm should be able to schedule observations. These observations are represented by the Exec Block (boxes labeled $EB_x$), each Exec Block may have different durations, as shown by the figure. If the algorithm is unable to allocate a observation in a time period then, the telescope operations software (or simulator) must skip certain amount of time, and then try again. The figure also shows a bug jump in time between $EB_3$ and $EB_4$, this represents the daily time not used for scientific operations.

\begin{figure}
\def\svgwidth{\textwidth}
\input{images/observation-schedule-representation.pdf_tex}
\caption{Representation of the observation schedule problem}
\label{fig:obs-schedule-representation}
\end{figure}

\subsubsection{Static parameters}
These parameters are statically provided at the beginning of the period. They do not change over the time period on which the algorithm calculates a valid solution.

\begin{description}
\item[$\mathbf{P_i}$] Project number $i$ $\Big\slash \forall P_i \mid P_i \neq \emptyset \land P_i = \{SB_{i1}, SB_{i2}, \ldots, SB_{ik}\}$.

\item[$\mathbf{SB_{ik}}$] Scheduling Block $k$ $\Big\slash \forall SB_{ik} | SB_{ik} \in P_i \land SB_{ik} \notin P_x \Leftrightarrow x \neq i$.

\item[$\mathbf{SciVal(P_i)}$] Scientific value for $P_i$ $\Big\slash \forall P_i \land SB_{ik} \in P_i \mid SciVal(P_i) \Leftrightarrow SciVal(SB_{ij}) $.

\item[$\mathbf{T(SB_{ik})}$] Duration (time) of a single execution (observation) for Scheduling Block $ik$.

\item[$\mathbf{AC_j}$] Array Configuration $j$.

\item[$\mathbf{T(AC_j)}$] Duration (time) for Array Configuration $j$.

\item[$\mathbf{Type(AC_j)}$] Type of Array Configuration number $i$ $\Big\slash Type(AC_j) \in \{12m, 7m, TP\}$.

\item[$\mathbf{Ex_h}$] Executive number $h$.

\item[$\mathbf{TP(Ex_h)}$] Percentage of time for Executive $h$ $\Big\slash \forall TP(Ex_h) \mid TP(Ex_h) \in {[0,1]} \land \sum_{h}^{n} TP(Ex_h) = 1$ 

\end{description} 

\subsubsection{Dynamic parameters}
Contrary to the static parameters, these parameters may change at any time during the time period being used by the algorithm.

\begin{description}
\item[$\mathbf{EB_n}$] Execution Block $n$. The execution blocks represents a time frame where an observation of Scheduling Block $SB_{ij}$ was carried on, it belongs to a given array configuration $AC_j $, since start time $t_s(EB_n)$ until end time $t_e(EB_n)$, during this period of time and array configuration the execution block is unique.

\item[$\mathbf{T(EB_n)}$] Duration (time) of Execution Block $n$.

\item[$\mathbf{LST}$] Current Local Sidereal Time.

\item[$\mathbf{St(P_i)}$] Current status of Project $i$  $
\left\{
\begin{array}{l l} 
true & \mbox{if  } P_i \mbox{ completed} \Leftrightarrow \forall SB_{ik} \in P_i \mid St(SB_{ik}) = true\\
false & \mbox{if  } P_i \mbox{ not completed} \\
\end{array}
\right .$

\item[$\mathbf{St(SB_{ik})}$] Current status of Scheduling Block $ik$  $
\left\{
\begin{array}{l l} 
true & \mbox{if  } SB_{ik} \mbox{ completed} \\
false & \mbox{if  } SB_{ik} \mbox{ not completed} \\
\end{array}
\right .$

\item[$\mathbf{\tau_{225}(SB_{ik}, t)}$] Opacity for a given Scheduling Block's source $ik$, for the given time $t$.

\item[$\mathbf{T_{sys}(SB_{ik}, t)}$] System temperature for a given Scheduling Block's source $ik$, for the given time $t$.

\end{description}

\subsubsection{Objective functions}

The main objective of the algorithm is to maximize the number of scientific projects completed at the end of the time frame given. Also it can be interpreted as to maximize the scientific value of the completed projects (see equation~\ref{eq:max-sci-value}). However there is a caveat, there must be priority on complete the best graded projects.

\begin{equation}
\label{eq:max-sci-value}
max \: \bigg(\sum_{i} SciVal(P_i) \times St(P_i)\bigg)
\end{equation}

At the same time the algorithm, must maximize the array's usage time. This is equivalent to minimize the array's idle time (see equation~\ref{eq:min-idle-time}).

\begin{equation}
\label{eq:min-idle-time}
max \mbox{ }\Bigg( \frac{\sum_{i}T(EB_i)}{T(AC_j)}\Bigg)
\end{equation}


\subsubsection{Constraints}
\label{sec:sched-constraints}
It is assumed that all the constraints operate over one or more Scheduling Block's properties, unless stated.

\begin{description}

\item[Executive time balance] \hfil \\
ALMA observatory is based on international collaboration. Within this collaboration several countries participate through science and astronomical organizations. Currently these organization are divided among different world's regions, which are called executives. These executives are North America (NA), Europe (EU), East Asia (EA), Chile (CL) and Non Alma members (OTHER).

Since each executive contributed with different resources, which may differ from the other executives. A fixed percentage of the total observation time of a observation cycle is given to each executive. Ideally, the assigned amount of observation time shall be adjusted to comply with the percentage assigned to each executive.

Ideally, the observation time percentage for each executive, has to be kept accordingly to the assigned percentage in the observation cycle. Nonetheless, this could carry unfairness within each observation sub-period (e.g within one week only NA Scheduling blocks were observed). This could trigger unhappiness and some concerns among the different executives, whom expects to have their observation time proportion assigned during a sub-period of time within the observation cycle.

It has been defined the period of time, as one week of observation (this coincides with the early science block carried on bi-weekly). Within this period of time each executive shall get as near as possible the amount of time assigned initially. If it is not possible, then the scheduler shall carry over the unfairness among the executive's times and apply corrections in future schedules (see equation~\ref{eq:exec-balance}).

\begin{equation}
\label{eq:exec-balance}
\frac{\sum_{i}^{n} T(EB_x)}{(t_e - t_s)} \approx TP(Ex_j) \mid  EB_i \in Ex_h \land t_s \leq t_s(EB_i) \land t_e(EB_n) \leq t_e
\end{equation}

Where $T(EB_x)$ is the time observed for a given Execution Block $EBxi$, $Ex_h$ is a given Executive; and $t_s$ and $t_e$ are the starting and ending times for a arbitrary time interval, as expressed before for convenience, this time interval may correspond to a single week of observations.

At the end of the cycle is expected that each Executive will receive the time assigned to it or a very near value. 

This constraint is a special kind, since it operates over a set of Execution Blocks after the observation of one or more Scheduling Blocks, over a period of time. Instead of operate over a Scheduling Block property.

\item[Right Array Type] \hfill \\
ALMA observatory will have several types of arrays. The algorithm must not choose the Scheduling Blocks which are not possible to observe on the current Array Type (equation~\ref{eq:array-type-sb}).

\begin{equation}
\label{eq:array-type-sb}
Type(AC_j) = Type(SB_{ik})
\end{equation}


\item[Source visibility] \hfill \\
It is possible to know before running the algorithm, to know if a point in the sky will be visible at the time when the algorithm runs.
In function of $LST$ the rising and setting, $LST_r$ and $LST_s$ shown by equation~\ref{eq:lst-r} and equation~\ref{eq:lst-s} respectively.
\begin{equation}
\label{eq:lst-r}
LST_r =  24 - \frac{1}{15} \cos^{-1} (-\tan\phi\tan\delta) + \alpha
\end{equation}
\begin{equation}
\label{eq:lst-s}
LST_s = \frac{1}{15} \cos^{-1} (-\tan\phi \tan\delta) + \alpha
\end{equation}

Also is possible to known if the source is always visible or hidden as shown in equation~\ref{eq:sky-src-always-vis} and~\ref{eq:sky-src-always-hid} respectively.

\begin{equation}
\label{eq:sky-src-always-vis}
visible \Leftrightarrow
\left\{
	\begin{array} {l l}
	\delta > (90^\circ - \phi) & \mbox{ for northern hemisphere} \\
	\delta < -(90^\circ + \phi) & \mbox{ for southern hemisphere} \\
	\end{array} 
\right.
\end{equation}
\begin{equation}
\label{eq:sky-src-always-hid}
hidden \Leftrightarrow
\left\{
	\begin{array} {l l}
	\delta < -(90^\circ - \phi) & \mbox{ for northern hemisphere} \\
	\delta > (90^\circ + \phi) & \mbox{ for southern hemisphere} \\
	\end{array} 
\right.
\end{equation}

where $\alpha$ is the right ascension, $\delta$ is the declination, and
$\phi$ is the telescope geographical latitude.


The selection operation selects all the SBs for which the current $LST$ falls
between $LST_r$ and $LST_s$, accounting for cases where this range extends to include
the following day (see equation~\ref{eq:lst-range-sel}).

\begin{equation}
\label{eq:lst-range-sel}
S(LST) = \left\{ 
	\begin{array}{l l}
	LST_r < LST < LST_s & \mbox{if } LST_r < LST_s \\
	LST_r < LST < 24 \land 0 \leq LST < LST_s & \mbox{if } LST_r > LST_s  \\
	true & \mbox{if } src(SB_{ik}) \mbox{ is always visible.} \\
	false & \mbox{if } src(SB_{ik}) \mbox{ is always hidden.} \\
	\end{array} \right .
\end{equation}

The $LST$ parameter is the current Local Sidereal Time, over what the algorithm is selecting Scheduling Blocks.

\item[Array configuration and resolution] \hfill \\
A first order approximation of the resolution that can be attained with a give
array configuration is $\theta = \lambda / l_{max}$ where $l_{max}$ is the maximum
baseline in the array. Each SB defines a range of acceptable resolutions $[\theta_{min}, \theta_{max}]$ (see equation~\ref{eq:sel-arr-res})
\begin{equation}
\label{eq:sel-arr-res}
\theta_{min} \leq \frac{\lambda}{l_{max}} \leq \theta_{max}
\end{equation}

\item[Atmospheric transmission] \hfill \\
For atmospheric transmission selection a simple criteria is used based in opacity quartiles at 225 GHz.

\begin{equation}
S(\nu_{rep}, \tau_{225}) = \left\{
    \begin{array}{l l}
    true & \mbox{if } \nu_{rep} > 370 \mbox{ GHz } \land \tau_{225} \leq 0.037 \\
    true & \mbox{if } 370 \mbox{ GHz } \geq \nu_{rep} > 270 \mbox{ GHz } \land \tau_{225} \leq 0.061 \\
    true & \mbox{if } \nu_{rep} < 270 \mbox{ GHz } \land \tau_{225} \leq 0.6\\
    false & \mbox{otherwhise}
    \end{array} \right . 
\end{equation}

where $\nu_{rep}$ is the representative frequency at $\tau_{225}$ is the Opacity
at Zenith at 225 Ghz.

\item[Weather stability] \hfill \\
During the execution of an observation, the algorithm must try to ensure that the weather conditions would not deteriorate significantly.
For this purpose, the $Tsys$ is calculated using an average of a few data
points taken at the time when the algorithm is executed, then this value is compared with the
projected $Tsys$ calculated at least 30 minutes later
%, taking also into consideration the change in elevation of the SB representative target.

How significant the increase in $Tsys$ needs to be for a SB to be discarded
is under discussion, and in general it will be frequency dependent. In addition
it is possible that some projects decide that non-optimum observing conditions are
fine anyway. For now, an increase in the $Tsys$  of 15-20\% is considered too much
degradation for the SB to be executed.

The selection operation filters out all the SBs that don't comply with equation~\ref{eq:sel-tsys}
\begin{equation}
\label{eq:sel-tsys}
\frac{T_{sys}(t+\Delta t) - T_{sys}(t)}{T_{sys}(t)} < 0.15
\end{equation}

\end{description}

\subsection{Algorithm design rationale}

So far, the study has been focused in the definition of the ALMA's Scheduling array problem and the study of its mathematical model. However, this have not provided the background about how the algorithm will operate internally to return a plan for a given time period. The decision of the algorithm design is driven by the following properties:
\begin{enumerate}
\item The algorithm must work on the on-line system and as well on simulation mode. The idea behind the simulation, is to evaluate how well (or bad) behave the algorithm for a given set of Scheduling Blocks, Array Configurations and time period. Since the ultimate goal is to use the algorithm in on-line system to contribute to take a decision for the best Scheduling Block at a given time.

\item The time within a time period, used by the algorithm, might not be discretized because of the variable duration of each Scheduling Block. Also a single execution of a Scheduling Block is not be preemptable until it completes (success ot failure). 

\item The algorithm must try to optimize the objective functions (equations~\ref{eq:max-sci-value} and~\ref{eq:min-idle-time}), but at the same time the executive percentage time balance must be kept in line, according to the original defined values, within an observation time frame of one (1) week (see equation~\ref{eq:exec-balance}).

\item The algorithm design and implementation must fit into lifecyle currently in use by ALMA software.

\end{enumerate}

Given the uncertain number of possible Execution Blocks, duration of them and the time when they are scheduled for execution, it might result impossible to determine a domain model where a complete search technique could be applied. Also, every time a Scheduling Block is scheduled for observation, the search tree for the problem changes, creating a whole new set of options based on the previous decision. Of course, the dynamism on the number of branches in the search tree, greatly depends on the number of Scheduling Block given as input for the algorithm. According to ALMA's system requirements the scheduling subsystem (including the algorithm) must be able to handle easily~\footnote{Easily is a quality property for the system, which should be interpreted as ``The algorithm must return a solution in a reasonable human time (usually between $1-2$ seconds)'' for the given input time} $10000$ Scheduling Blocks as input.

The algorithm proposed in this study will be based on the Deficit Round-Robin (DRR) algorithm~\cite{shreedhar96}. The original algorithm defines service flows (queues) and a processor dispatching the network packets arrived and already sorted in one of the flows. Making a comparative between the model proposed in the original paper and the ALMA's scheduling problem, it is possible to map the original proposed domain model into the ALMA's model as follows:

\begin{description}
\item[Network packets] are mapped into a \textit{single-execution of a Scheduling Block}. This is not the same as the Execution Block, because this entity is the result after a Scheduling Block execution. As established by DRR design, the network packet length is variable, matching the single-execution time Scheduling Block property.

\item[Processor] is mapped into the \textit{Array Configuration}. The Array is unique and can execute just one Scheduling Block at a given time.

\item[Service flows] are mapped into the \textit{Executives' observation times}. Actually, the flows will be mapped into the percentage of the Executives' observation times, what is a measurable quantity given an arbitrary time frame inside the total duration of the time given as input to the algorithm. Nevertheless, the mapping here does not fit perfectly, due the design of DRR establishes that every service flow will have the same priority than the others. For the ALMA case, each Executive should have different priorities, to deal with this issue a weight will be applied to the quantum size, based on the time percentage assigned to each executive, this is similar to what is proposed in the weighted Round-Robin algorithm explained in~\cite{katevenis91}.
\end{description}

The quantum size will be fixed number as explained in the original DRR design. However, the quantum size applied to a Executive's service flow will be multiplied by a weight defined in equation~\ref{eq:alg-quantum-weight}, which is different for every Executive.

\begin{equation}
\label{eq:alg-quantum-weight}
W_{h} = \frac{TP(Ex_h)}{max(TP(Ex_x))}
\end{equation}

The initialization of the DRR algorithm proposed is detailed in listing~\ref{alg:drr-init}. The initialization procedures sets the weighted quantum for each participant executive.

\begin{algorithm}                     
\caption{Deficit Round Robin initialization}          
\label{alg:drr-init}                   
\begin{algorithmic}                    
    \REQUIRE $ExecPercentage_i > 0$ and $Q > 0$
    \ENSURE $EQ_i > 0$
    \STATE $MaxQFactor = 1 / max(ExecPercentage)$
    \FOR{$i=0$ to $n$}
    \STATE $EQ_i = ExecPercentage_i\times MaxQFactor \times Q$
    \STATE $DC_i = 0$ \COMMENT{Deficit counters}
    \STATE $RRp = 0$ \COMMENT{Round robin pointer initialized to point ot the first Executive service queue}
    \ENDFOR
\end{algorithmic}
\end{algorithm}

In the original DRR algorithm, the service flows are filled with network packets arriving from the media, and they are kept in the queues until they are dispatched. In ALMA, each service flow will be filled with the result of the Scheduling Block filtered for the given time based on the mathematical model constraints explained in section~\ref{sec:array-sched-math-model}. The difference with DRR is that the service flows will be recalculated every time the algorithm runs, filtering-out and putting-in the no longer and new suitable Scheduling Blocks respectively. The queuing mechanism is presented in listing~\ref{alg:drr-queuing}.

\begin{algorithm}                     
\caption{Deficit Round Robin queuing}          
\label{alg:drr-queuing}                   
\begin{algorithmic}                    
    \REQUIRE $size(ScoredSBs) > 0$
    \FOR{$i=0$ to $size(Executives)$}
    \STATE $clean(Queue_i)$
    \ENDFOR
    \STATE $sort(ScoredSBs)$
    \FOR{$i=0$ to $size(ScoredSBs)$}
    \STATE $E = Exec(ScoredSBs_i)$
    \STATE $insert(Queue_E, ScoredSBs_i)$
    \ENDFOR
\end{algorithmic}
\end{algorithm}

To achieve the objective functions, the algorithm must optimize the selection for the given time. For this reason, the Scheduling Blocks must be prioritized according to a score. This score shall be composed by the sum of different weighted scores, very similar to what is proposed in the current ALMA algorithm. The following are the scorers currently defined for the current ALMA DSA, that can be reused for the proposed algorithm in this study:

\begin{description}
\item[Scientific priority score] \hfill \\
Each proposal or project gets assigned a scientific priority, defined by three numbers
(score, rank, grade). The \texttt{score} (a float) is assigned by
a specialized committee (galactic, extra-galactic, etc.). When the proposals that have
been evaluated by different committees are assembled in one set, there is the possibility
of collisions in the order defined by the \texttt{score}. The \texttt{rank} (an integer) resolves these
collisions, providing a completely ordered set. On top of this, the \texttt{grade} (which can assume
the values A, B, C, or D)

The algorithm computes the scientific priority score as shown in equation~\ref{eq:project-grade-score}
\begin{equation}
\label{eq:project-grade-score}
S = \frac{N_p - (\mathtt{rank} - 1)}{N_p} + K
\end{equation}
where $N_p$ is the total number of projects (or proposals), and $K$ is defined by equation~\ref{eq:scoring-prj-grades}
\begin{equation}
\label{eq:scoring-prj-grades}
K = \left\{
    \begin{array}{l l}
    4 & \mbox{if project grade is $A$} \\
    2 & \mbox{if project grade is $B$} \\
    1 & \mbox{if project grade is $C$} \\
    0 & \mbox{if project grade is $D$}
    \end{array} \right . 
\end{equation}

\item[Hour angle score] \hfill \\
In order to favor the Scheduling Blocks that at the current time have their representative source close to the zenith, 
their hour angle should be in the vicinity of $0.0$ hours. The hour angle score is defined in equation~\ref{eq:ha-scorer}

\begin{equation}
\label{eq:ha-scorer}
	S = \frac{AM_{current}}{AM_{transit}} = \frac{\cos(HA) + \tan(\delta) \tan(\varphi)}
											{1 + \tan(\delta) \tan(\varphi)}
\end{equation}

Where $AM$ is the Air Mass at transit (at source meridian transit) and current (current value of $AM$ if observed), $HA$ Hour Angle, $\delta$ target declination and $\varphi$ latitude of ALMA

\item[Weather selector] \hfill \\
This selector is based on the $T_{sys}$ as shown by equation~\ref{eq:weather-scorer}
\begin{equation}
\label{eq:weather-scorer}
	S_{T_{sys}} = \frac{T_{sys}^{transit}}{T_{sys}^{current}}
\end{equation}
\end{description}

Therefore, every Scheduling Block queued into the service flow is given a score represented by equation~\ref{eq:sb-final-score}. Given this, every Scheduling Block is inserted in order into the service queue, selecting just the top Scheduling Block from the serviced executive at a given time.

\begin{equation}
\label{eq:sb-final-score}
\sum_{i}^{n} w_i\times Sc_i(SB_{xy})
\end{equation}

The DRR proposed is presented in listing~\ref{alg:drr-select}. Nevertheless one extra complication is expected, the original DRR is designed for continuous operation. In the case of ALMA, the software must have to define provisions to save the deficit counters and current round-robin pointer, due the algorithm is suspended every time after a selection is done. In the case of the simulation, this is not a problem because these variables can be saved as long the simulator instance remains in memory.

\begin{algorithm}                     
\caption{Deficit Round Robin selection}          
\label{alg:drr-select}                   
\begin{algorithmic}                    
    \REQUIRE $Queue[i] > 0$ and $i = 0$
    \ENSURE $selectedSB \neq null$ and $store(RRp)$ and $store(prevRRp)$
    \REPEAT
    \STATE $i = i + 1$
    \COMMENT{Ensure that the previous exectuive selected increases its deficit counter after a loop over all the other executives without finding a SB to return}
    \IF{$ i > size(Executives)$}
    \STATE $prevRRp = null$
    \STATE $i = 1$
    \ENDIF
    \IF{$prevRRp \neq RRp$}
    \STATE $DC_{RRp} = EQ_{RRp} + DC_{RRp}$
    \ENDIF
    \IF{$size(Queue_{RRp} = 0)$}
    \STATE  $RRp = next()$
    \ENDIF
    \IF{$ObsTime(top(Queue_{RRp})) < DC_{RRp}$}
    \STATE $SelectedSB = top(Queue_{RRp})$
    \STATE $DC_{RRp} = DC_{RRp} - ObsTime(SelectedDbs)$
    \STATE $prevRRp = RRp$
    \ENDIF
    \UNTIL{$selectedSB \neq null$}
    \RETURN  $SelectedSB$
\end{algorithmic}
\end{algorithm}


\section{ALMA's Array configuration planning problem}
\label{sec:array-config-plan}
This problem depends upon the result of the algorithm output for the ``Scheduling Array'' sub-problem as illustrated on figure~\ref{fig:array-config-problem-overview}. This problem is part of the ``ALMA's  long-term scheduling problem'', therefore multiple Array configurations are considered as input.
\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{images/array-config-problem-overview}
\end{center}
\caption{Array configuration schedule problem overview}
\label{fig:array-config-problem-overview}
\end{figure}

\subsection{General conditions and assumptions}
\label{sec:array-problem-general-condition}
The problem will consider 3 different possible Array types: \textit{12-meter arrays} ($12m$) intended to be used in together with the baseline correlator computer, \textit{7-meter arrays} ($7m$) intended to be used together with ACA correlator computer (zero-spacing interferometer) and \textit{Total Power arrays} ($TP$) intended to use in auto-correlations (single-dish). 

The array configurations duration has been discretized in terms of weeks. Keeping the configurations with shorter durations may be introduce a lot of overhead for operations, due in every configuration change several antennas might be moved from one pad to another, using valuable time not destined to science.

The antenna movement duration among pads is not considered in the model.

The algorithm will not propose changes in properties of the array configurations (e.g. angular resolution, number of antennas, bands available, etc). It will only propose changes in terms of duration and staring time.

Science observations will be carried over a daily time period considerably less than 24 hours. If there was 24 hours operations for every array, then this problem would be reduced to calculate the sum of the hours requested by every relevant project assigned to a every array configuration, as the requested array duration.

\subsection{Mathematical model}

A generic representation of the model proposed is presented in figure~\ref{fig:array-planning-representation}. There the different array configurations are scheduled over the season presented in the horizontal coordinate as a time-tile each one of the separation along the time-line represents a month. A configuration can be scheduled more than once over the season like the $12m_1$ configuration in the diagram, and a configuration can spawn for the whole season, if there are no conflicting arrays configurations, like the $TP$ in the representation.

\begin{figure}
\def\svgwidth{\textwidth}
\input{images/array-config-problem-representation.pdf_tex}
\caption{Representation of the array configuration planning problem}
\label{fig:array-planning-representation}
\end{figure}

\subsubsection{Parameters}
\begin{description}
\item[$\mathbf{AC_i}$] Array Configuration number $i$.

\item[$\mathbf{Type(AC_i)}$] Type of Array Configuration number $i$ $\Big\slash\: Type(AC_i) \in \{12m, 7m, TP\}$.

\item[$\mathbf{t_s(AC_i), t_e(AC_i)}$] Start and end date, respectively, for Array Configuration number $i$ $\Big\slash\: t_s(AC_i) < t_e(AC_i)$.

\item[$\mathbf{td_s(AC_i), d(AC_i)}$] Daily start time and duration of the daily period, respectively, for Array Configuration number $i$. $\Big\slash\: d(AC_i) \ll 24\;[h]$.

\item[$\mathbf{Gr(P_i)}$] Grade given to the project $i$ $\Big\slash\: Gr(P_x) \in \{A,B,C,D\}$, where $A$ denotes the highest grade and $D$ the lowest grade.
\end{description}

\subsubsection{Objective function}
The main objective of the algorithm for this problem is to try to complete the highest scientific graded projects as shown by the equation~\ref{eq:array-max-a-graded-projects}.
\begin{equation}
\label{eq:array-max-a-graded-projects}
max \: \bigg(\sum_{i} St(P_i)\bigg) \:\: \mid\; \forall Gr(P_i) = A
\end{equation}

\subsubsection{Constraints}
\begin{description}
\item[Array configurations duration overlap] \hfill \\
The antennas and the correlator computers are unique instrument components that can be present in just one array configuration at the very same time. Hence, to avoid duplication of resources, just one type of array configuration of the same type is allowed at a given time period. There is one exception, the Total power arrays, but for simplification it is considered as the other configuration types. The constraint can be expressed as shown by equation~\ref{eq:array-uniqness}

\begin{equation}
\label{eq:array-uniqness}
t_s(AC_j) > t_e(AC_i)\; \veebar \; t_e(AC_j) < t_s(AC_i) \:
\Big\slash \: \forall AC_i, AC_j \mid Type(AC_i) = Type(AC_j)
\end{equation}

Given that, it is possible to deduce that there are maximum three (3) arrays configurations running simultaneously, one for each array configuration type.

\item[Array Configuration minimum lifespan] \hfill \\
The minimum duration for a given Array Configuration must be 4 weeks (equation~\ref{eq:min-array-lifespan}). This is to avoid time overheads spent changing between configurations. Even when the algorithm make no provisions about the time spent in those changes, this is implicitly expressed in this constraint.

\begin{equation}
\label{eq:min-array-lifespan}
t_e(AC_i) - t_s(AC_i) \geq 4\:weeks
\end{equation}

The observatory can setup several times, at different dates, over the observing season the same array configuration. For simplification, the model does not identify each one of these repetitions as the same array configuration, because the start and end date differs from the same configuration scheduled in another dates. In fact, they are considered different instruments even when they offer the same capabilities.

\end{description}

\subsection{Scheduling Block classification}
\label{sec:array-sb-classification}
From section~\ref{sec:sched-constraints}, it is possible to deduce that, there is a subset of these restriction which might help to narrow the search space for this problem. In fact, it may be possible to define a ``Scheduling Block critical subset'', inherent to each Array Configuration. Although the Scheduling Blocks belonging to one array configuration could not be exclusive to it.

The list of constraints is the following:
\begin{enumerate}
\item Array type (equation~\ref{eq:array-type-sb})
\item Source visibility (equation~\ref{eq:lst-range-sel})
\item Array configuration and resolution (equation~\ref{eq:sel-arr-res})
\end{enumerate}
These criteria must be applied only over $A$ graded projects and their belonging Scheduling Blocks, as defined by the objective function.

For the list items 1. and 3., it is possible to see that the SB selection for them is quite straight-forward. However for 2., the LST range may vary widely, depending of the sky source. Also, a correlation between the LST requested, in the Scheduling block, and the array date schedule must be found to narrow the array starting points and duration.

\subsection{Source visibility analysis}
From~\cite{meeus98} the altitude of a certain sky source is defined as shown by equation~\ref{eq:source-altitude}
\begin{equation}
\label{eq:source-altitude}
sin(h) = sin(\varphi) sin(\delta) + cos(\varphi) cos(\delta) cos(H)
\end{equation}
Where $h$ is the altitude, positive above the horizon, negative below; $\varphi$ is the observatory's latitude, positive is in northern hemisphere, negative in southern hemisphere; $\delta$ is the declination of the source, positive is north of the celestial equator, negative if south; and $H$ is the local hour angle, measured westwards from the South.

$H$ is calculated as shown by equation~\ref{eq:hour-angle-calculation}
\begin{equation}
\label{eq:hour-angle-calculation}
H = \theta - \alpha
\end{equation}
Where $\theta$ is the Local Sidereal Time (LST) and $\alpha$ is the right ascension of the sky source, usually it is expressed in terms of hours, minutes and seconds.

From these equations is possible to derive that the highest altitude in the sky is reach when $H = 0$. Or expressed in terms of LST, when $\theta = \alpha$. At this point is when there are less atmosphere between the observatory and the sky source, hence the quality of the data taken is better.

Nevertheless also it is possible to observe a sky source 
while it is not at its highest altitude in the sky, the key is to set a minimal altitude to allow to carry on observations properly. This minimum allowed altitude for ALMA observatory is set to $15^\circ$ mostly due to the surrounding mountains around the site. 

\subsubsection{Array Configuration duration and LST relationship}
As stated in the general condition in section~\ref{sec:array-problem-general-condition} the minimum resolution for the problem is one (1) week.

From the algorithm used to calculate the LST found in~\cite{kaplan05}, it is possible to deduce that the LST drifts from the calendar time. The drift calculated rate is approximately $1654.7328\,[s]$ or $27.57888\,[min]$ ahead for every calendar week.

Therefore, the LST interval during the minimum array lifespan (of 4 weeks) will be approximately the number of hours in the daily time interval plus $1.838592\;[h]$.
Of course the borders of the configuration interval, in LST terms, would not be available the whole array duration due to the LST drifting, and these LST hours will have less representation as the array configuration life advances. But for a crude estimation of the LST interval available during array configuration life, works fine.

The minimum configuration duration set by the problem and its model definition (4 weeks), may be changed according to the total time requested by the Scheduling Blocks covered under the calculated LST range for the given array configuration. Then, the array configuration lifespan could be either the minimum duration defined by the problem, or the total time requested by the Scheduling Blocks, or a value between both.

\subsection{Algorithm design rationale}
\label{sec:acpp-sa-alg-design}
The search space of the problem is related to the combinations that each array configuration's start date and duration can produce, modifying either its start time, duration or both, during the span of the whole observing season as shown by equation~\ref{eq:one-array-search-space}

\begin{equation}
\label{eq:one-array-search-space}
\sum_{i=4}^{MaxDuration} \Big(MaxDuration - i\Big) 
\end{equation}

Considering a whole year ($52\,[weeks]$) and just one array configuration there are $\Sigma_{i=4}^{52} (52 - i) = 1128$ different starting dates and duration for the array configuration. Adding more array configurations make the number of possibilities to explode exponentially.

Using the Scheduling Block classification method described in section~\ref{sec:array-sb-classification} might help to reduce the search space, defining a ``Scheduling Block critical set'' for each array configuration.
Nevertheless the effectiveness of the method is not guaranteed, given the scheduling blocks' sky source dispersion over the sky, in particular over the Right Ascension coordinate for a given array configuration.

The algorithm needs to be able to explore the search space given by the different starting dates for the array configurations, as well the different durations. But once it finds a good solution, the algorithm must optimize that based on the best-found solution until now, to try complete as much projects as possible. For this reason, this work propose to solve this problem implementing a Simulated annealing algorithm.

At the start the algorithm must able to map the requested LST ranges of each array configuration, into an interval of a calendar dates. This mapping will depend on the adjustments given for the Observation season: its start time and its duration. This could return multiple calendar dates indicating when the array configuration can start. A ``random'' greedy algorithm is defined in~\ref{alg:array-greedy}, which will return a plan for the array configuration over the observation season.
\begin{algorithm}[h!]
\caption{Greedy Algorithm used for random restarts in Array configuration planning problem solution}          
\label{alg:array-greedy}                   
\begin{algorithmic}                    
    \REQUIRE $ArrayConfigsSet \neq \varnothing $ and $LSTIntervals_{ArrConf} \neq \varnothing$ and $minACDur = 4\,weeks$  and $MAX\_ITER$
    \ENSURE $ArrayConfigSchedule \neq \varnothing$
    \STATE $ArrayConfigsPropStartDates = calculateCalendarDates(ArrayConfigSet, LSTIntervals)$
    \REPEAT 
    \STATE $ac = random(ArrayConfigsSet)$
    \STATE $lst = random(LSTIntervals_{ac})$
    \IF {$isLSTAlreadyUsed_{lst}$}
    \STATE $nChecks = nChecks + 1$
    \ELSE
    \STATE $startDate = random(ArrayConfigsPropStartDates_{ac})$
    \STATE $endDate = startDate + randomNumberOfweeks() + minACDur$
    \STATE $collision = checkForIntervalCollisions(ArrayConfigSchedule, startDate, endDate)$
    \IF{$collision = false$}
    \STATE $add(ArrayConfigSchedule, ac, startDate, endDate)$
    \STATE $nChecks = 0$
    \ELSE
    \STATE $nChecks = nChecks + 1$
    \ENDIF
    \ENDIF
    \UNTIL {$nChecks = MAX\_ITER$}
    \RETURN $ArrayConfigSchedule$
    \end{algorithmic}
\end{algorithm}

This greedy algorithm is random in the sense to choose what array configuration is selected to operate over it. Once one of them is selected, one of the start dates in selected, also randomly. There may be conflicts with other already scheduled array configurations, but this algorithm does not has the ability to resolve these conflicts, it just ignore them and continues trying to allocate others array configurations, randomly.

This should give enough combinations, as return values, where a more intelligent algorithm could operate over them. Nevertheless, the lack of a more smart resolution over the array configurations schedule conflicts, may not consider certain valid solutions or it could take several invokes to the proposed greedy algorithm to give it, since it is just random-based. 

A simulated annealing algorithm may help to fine tune the solution returned by the greedy algorithm. The proposed algorithm is shown is listing~\ref{alg:array-sa}.
\begin{algorithm}                     
\caption{Simulated Annealing Algorithm used as solution for Array configuration planning problem}          
\label{alg:array-sa}                   
\begin{algorithmic}                    
    \REQUIRE $ArrayConfigsSet \neq \varnothing $ and $LSTIntervals_{ArrConf} \neq \varnothing$ and $N\_ITER$ and $0 < nAGradedPjrsCompleted \leq TOTAL\_A\_GRADED\_PROJECTS$
    \ENSURE $BestArrayConfigPlan \neq \varnothing$
    \REPEAT
    \IF{$CompletedAPrjs(currSol) \geq nAGradedPjrsCompleted $}
    \RETURN $currSol$
    \ENDIF
    \IF{$random() < 0.5$}
    \STATE $next = neighbor(currSol)$
    \ELSE
    \STATE $next = findInitialSolution(ArrayConfigsSet, LSTIntervals)$
    \COMMENT{Call greedy algorithm defined in listing~\ref{alg:array-greedy}}
    \ENDIF
    \STATE $nextValue = runSimulation(next)$
    \STATE $\Delta E = currValue - nextValue$
    \IF{$\Delta E > 0$}
    \STATE $best = next$
    \STATE $current = next$
    \STATE $currValue =  nextValue$
    \ELSE
    \STATE $T = (N\_ITER - i) \times MAX\_VALUE$
    \IF{$e^{\frac{\Delta E}{T}} > random()$}
    \STATE $current = next$
    \STATE $currValue =  nextValue$
    \ENDIF
    \ENDIF
    \UNTIL {$i = N\_ITER$}
    \RETURN $best$
    \end{algorithmic}
\end{algorithm}

The idea behind the design or the proposed SAA is to fine-tune the solution found by the greedy algorithm, exploring the neighborhood of the given solution. Of course, the SAA defined also will jump, trying to explore into solutions that are not part of the neighbor, using as random restart a result from the invocation of the proposed greedy algorithm, again. The SAA will iterate until it found a feasible solution for the requested problem, which is: ``Find a array configuration plan to complete $N$ number of A-graded projects'', where $N < TOTAL\_A\_GRADED\_PROJECTS$; or when iterates reaching the $N\_ITER$ limit.

The possible movements that SAA can execute to alter the initial solution are discussed next, as follows:
\begin{description}
\item[Change the start date for a given Array Configuration] This is considered a medium-change, it may allow to the solution to partially jump-out from the LST interval where there are more observable scheduling block. The contrary is also possible, but not both together, unless the configuration duration is also increased. The proposed SAA implements this, selecting randomly the Array Configuration.

\item[Change the duration for a given Array Configuration] This is considered a soft-change, increasing the duration will affect positively to the solution because will allow to more Scheduling Blocks be observed, even more of them can be completed. The proposed SAA implements this, selecting randomly the Array Configuration and the start or end time to modify. But first, for the selected array configuration whether it is feasible to extend its duration checking, if there are no conflicting array configurations in the surroundings or not.

\item[Swap two conflicting Array Configurations for given dates] This is the harshest modification for the solution. The SAA proposed will not implement it, since relies completely on the proposed greedy algorithm for this. This modification cannot be applied if there are not conflicting array configurations in the interval desired to modify. This movement can be seen as a combination of the both movements described above, but also can involve swapping order for the array configurations in a clever way to see whether the new solution is better or not.
\end{description}

