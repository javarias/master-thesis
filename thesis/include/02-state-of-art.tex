\chapter{State of the art}

The scheduling problem is an optimization problem in which ideal jobs, also called tasks, are assigned to resources at particular times to execute these jobs, the execution of the jobs must satisfy all the constraints, this should be done in a way that the resulting schedule, the solution, is the best possible.

The most well known problem is the \textit{job-shop} scheduling problem presented by first time in 1966 by Graham \cite{graham66}. The objective of this problem is to complete a set jobs, each of which consists of a sequence of actions, where each action has a given duration and might require some resources. The problem is to determine a schedule that minimized the total time required to complete all the jobs, while respecting the resource constraints~\cite{russell03}.

The job-shop dynamic scheduling problem has been researched in the recent years, there are different classifications given to the problem based on the dynamism related to constraints or related to the jobs. A full survey can be found in~\cite{ouelhadj}. Also different methods are discussed to solve the problem.

\section{Fair scheduling: Processor sharing approach}

Another approach to scheduling problem is the proportional fair scheduling studied at level of processor sharing, this problem is very common in computer science and developing of Operating System's kernels~\cite{li09} including real-time systems and in the past, in the 90's was studied in network sharing~\cite{parekh93}. 

In this problem fairness is an essential requirement of the scheduler designed for the operating system. The conventional approach is to assign to each task a weight and the scheduler ensures that each task receive time proportional to its weight~\cite{katevenis91, parekh93}. Since perfect fairness requires infinitesimal small scheduling quanta, which is unfeasible, all practical schedulers approximate it with the goal of obtaining small error bounds. Although this method to achieve fairness, requires that the task to be preemptible, which is always not feasible to do. In case that the jobs must be serviced as whole units, the Deficit Round-Robin algorithm can be applied~\cite{shreedhar96}. 

Most of the modern operating system have been adopted an imprecise notion of fairness that seeks prevention of the starvation and be ``reasonable'' fair at the same time~\cite{li09}. In these designs the scheduler dispatches threads in the order of threat priorities. For each thread, it assigns the threads a time slice that determines how long the thread can run once the thread dispatched. A higher priority thread receives a larger time slice, how much larger is often determined empirically, not a proportional function of the thread's priority. To facilitate fairness the scheduler also dynamically adjusts priorities, allowing the priority of a thread to decay over time or boosting it if the thread have not run for a while. Similar to time slices, the parameters of these adjustments are determined empirically using heuristic methods. 

The most recent work have used different kind of techniques to achieve a fairer algorithm than previous one e.g. Virtual-time-based algorithm, lottery algorithms. However most of the recent work has been done used the Round-Robin algorithm technique. Round-Robin algorithms have $O(1)$ time complexity and thus are highly efficient~\cite{li09}. However they have weak fairness with $O(N)$ lag bounds in general. Currently Linux kernel is using the Completely Fair Scheduler~\cite{jones09}, which could it be a misleading name because it guarantees a unfair level less than $O(n)$ which is not completely fair. 

\subsection{Fair scheduling theory}
Generalized Processor Sharing (GPS) is an idealized scheduling algorithm that achieves perfect fairness. All practical schedulers approximate GPS and use it as reference to measure fairness.

Consider a system with $P$ CPUs and $N$ threads. Each thread $i$, $1 \leq i \leq N$, has a weight $w_i$. A scheduler is perfectly fair if:
\begin{enumerate}
	\item It is work conservative i.e., it never leaves a CPU idle if there are runnable threads.
	\item it allocates CPU time to threads in exact proportion to their weights.
\end{enumerate}
Such scheduler is common referred as GPS~\cite{parekh93}.

\newtheorem{gps-model}{Definition}
\begin{gps-model}
A GPS scheduler is one for which
$$\frac{S_i(t_1, t_2)}{S_j(t_1, t_2)} \geq \frac{w_i}{w_j}, j=1, 2, ..., N$$
holds for any thread $i$ that is continuously runnable in $[t_1, t_2]$ and $w_i$ and $w_j$ are fixed in that interval. 
\end{gps-model}

\newtheorem{gps-props}{Property}
\begin{gps-props}
If both threads $i$ and $j$ are continuously runnable with fixed weights in $[t_1, t_2]$, then GPS satisfies 
$$\frac{S_i(t_1, t_2)}{S_j(t_1, t_2)} = \frac{w_i}{w_j}$$
\end{gps-props}

\begin{gps-props}
If the set of runnable threads, $\Phi$, and their weights remain unchanged throughout  the interval $[t_1, t_2]$, then for any thread $i \in \Phi$, GPS satisfies
$$S_i(t_1, t_2) = \frac{w_i}{\sum_{j \in \Phi} w_j}(t_2 - t_1)P$$
\end{gps-props}

For multiprocessor some weights assignments can be unfeasible  and thus no GPS scheduler can exist, then Chandra et al.~\cite{chandra00} introduced the following definition:

\begin{gps-model}
In any given interval $[t_1, t_2]$, the weight $w_i$ of thread $i$ is unfeasible if
$$\frac{w_i}{\sum_{j \in \Phi}w_j} > \frac{1}{P},$$
where $\Phi$ is the set of runnable threads that remain unchanged in $[t_1, t_2]$ and P is the number of CPUs.
\end{gps-model} 

An unfeasible weight represents a resource demand that exceeds the system capability. Chandra et al.~\cite{chandra00} propose to convert unfeasible weights into their closest feasible ones. With this conversion, a GPS scheduler is well defined for any multiprocessor system.

A GPS scheduler is idealized since all runnable threads must run simultaneously and be scheduled with infinitesimally quanta, which is unfeasible. Thus, all practical scheduler emulate GPS approximately and are evaluated from two aspects: fairness and time complexity. Lag is common used metric for fairness. Assume that threads $i$ and $j$ are both runnable and have a fixed weight in the interval $[t_1, t_2]$ under some algorithm A.

\begin{gps-model}
For any interval $[t_1, t_2]$, the lag of thread $i$ at the time $t \in [t_1, t_2]$ is
$$lag_i(t) = S_{i, GPS}(t_1, t) - S_{i, A}(t_1, t).$$
\end{gps-model}

A positive lags at time $t$ implies that the thread has received less service than under GPS; a negative lag implies the opposite. All fair scheduling algorithm seek to bound the positive and negative lags, the smaller the bounds are the fairer algorithm. An algorithm achieves strong fairness if its lags are bounded by small constants. On other hand, fairness is poor and non-scalable if the lag bounds are $O(N)$ function , where N is the number of threads, because the algorithm  increasingly deviates from GPS as the number of threads in the system increases.

\section{Scheduling of Astronomic Observations}

Astronomical observations require specific conditions and goals for their execution. All this information, together with the scientific goals of the observation, are presented by an astronomer in a so called \textit{proposal to apply for observation time}. Its format can vary from one institution to another, including the following parameters: telescope and instrument (one telescope can work with more than one instrument), main investigator, program description and target(s) list. In particular the case of the ALMA project data model (APDM), this project model has been achieve in a joint effort between several astronomical institutions.

For Chile, there are three main institutions managing some of the world’s most important telescopes: European Southern Observatory, ESO (La Silla, Paranal, APEX); Association of Universities for Research in Astronomy, AURA (Tololo, Gemini, SOAR); and Observatories of the Carnegie Institute of Washington, OCIW (Las Campanas). Proposals have to be sent to the corresponding telescope Time Assignment Committee, which evaluates all proposals, assigning a scientific grade (importance of execution), and approving or rejecting the requested observing times. Since most observatories are joint ventures between several organizations and/or countries, the list of approved projects has to comply with the percentage of total time assigned to each executive. Normally, telescope time can be applied once per observation period. An observation can be executed in visitor or service mode. Visitor mode observations require the presence of the main investigator (or a collaborator) on site to take the data, while service mode observations are executed by the telescope operator and observatory’s science staff members.

The scheduling of astronomical observations is a variation of the dynamic scheduling problem, which has been treated in various ways since several decades by the scientific community as discussed in \cite{gomez03}. This is a multi-objective problem, as normally various optimizations are required. The most important ones are the maximization of the executed scientific priorities (scientific throughput), and the maximization of observing time usage. This could include minimizing gaps between executions (including readout time, telescope movement to the new source, instrument change and/or calibrations, etc.), and carefully planning required maintenance. Also, the total exposure time of an observation may depend on atmospheric conditions, as it could be necessary to do larger exposures with poor visibility.

Although most of modern professional observatories use certain degree of scheduling automation, there is still a huge part of human intervention to build up the daily plan and to take last minute decisions. External parameters can vary at any time during observations, and therefore a dynamic re-scheduling is needed. If we consider a given execution priority for each block, depending on the quality of observation conditions and importance of scientific goals, external parameters can certainly cause priority changes: some observations may not be suitable anymore to execute under new conditions. Moreover, as observation blocks depend on target’s visibility on the sky, they might be only valid during certain day/night time, and/or certain periods of the year. Therefore, it might happen that initially high priority tasks have to be executed with less priority, or cannot be executed at all within one observation period. Particular observation blocks may also depend on others to be executed. For example, it may be required to execute blocks sequentially or with a certain frequency.

\section{Current observatory schedulers}

A good description of the common astronomy scheduling problem and basic mathematical model is presented in \cite{gomez03}. In the same publication, the author proposes long and short-term scheduling scopes, and tries to solve the problem using neighbourhood search (Lin-Kernighan heuristic) and genetic algorithms. The result is that under certain circumstances (short size and good pre-ordered sample) the neighbourhood search can perform better than the genetic algorithm. Nevertheless, the genetic algorithm is in general a better and faster alternative, and does not need a pre-knowledge of the main constraints. The scientific policy imposes some restrictions that are difficult to handle, depending strongly on the sample characteristics (proposal quality and duration). To take better advantage of automatic scheduling, it is important to have a small degree of over-subscription in the final allocated time, and also a large number of short exposure (duration) project proposals.

The most referenced scheduling solution for astronomical observations is the SPIKE scheduler for the Hubble Space Telescope, developed by the Space Telescope Science Institute (STScI). SPIKE is largely cited as a reference scheduling system, and has also been adapted to other (ground based) telescopes. The current trend is to increase the observations automation, as astronomical projects are getting more complex, observation time more expensive, and decisions more difficult.

\subsection{Hubble Space Telescope}
The Hubble Space Telescope is probably the most famous space telescope, launched in 1990, and best known for its exploration of the deep space from the Earth orbit. It is a collaboration between NASA and the European Space Agency. Space telescopes have the advantage of not depending on atmospheric interference, but are also much more complex to maintain and repair. The HST SPIKE scheduling system, described in \cite{johnston90} and \cite{zweben94}, treats the scheduling as a constraint satisfaction problem (CSP), including a toolkit to handle this type of problems. Short and long term scheduling concepts are applied, and several schedule steps are considered: trial assignment heuristic (min-conflicts times), repair heuristic (neural network) and de-conflict (priority selection). Also, rescheduling of observations is possible through the CSP toolkit (task locking and conflict-cause analysis). Since its original implementation in 1987 SPIKE is entirely implemented in Common Lisp and Common Lisp Interface Manager for user interfaces. \cite{muscettola96} presents a report about studies related to the generalization of constraint-based scheduling theories and techniques with application to space telescope observation scheduling. For this goal, the Heuristic Scheduling Testbed System (HSTS) planning and scheduling framework was developed. Planning and scheduling are treated as complimentary problems to produce good results.

\subsection{Very Large Telescope}
The VLT, operated by ESO, is one of the world's largest optical telescopes, with four 8.2 meter aperture telescopes, designed to work separately or as a single instrument: the VLT Interferometer. It is located in the northern Chilean dessert, on top of the Paranal mountain. The early observations plan for the VLT is discussed in~\cite{johnston88}, describing the SPIKE scheduling tools, initially developed for the HST, and the requirements to adapt it for VLT use and other ground based observatories. The automated scheduling is thought just as an assistant for human decisions on value judgments, mixing visitor and service mode observations. Nevertheless, it is an important step starting from the visitor only mode in La
Silla. Also, first concepts of artificial intelligence are introduced, and envisioned as a good way to significantly reduce calculation times. Later, \cite{silva02} describes the proposal selection, prioritizing and scheduling process at ESO observatories.
Specially interesting is the mention of many factors that normally affect observations, such as time of the year, technical down-time and lunar phase (brightness). Observations are organized in periods of 6 months each.

\subsection{Gemini Observatory}
The Gemini Observatory is made up of two almost identical 8.1 meters telescopes, located in both hemispheres: Chilean Pach\'on mountain and Hawaiian Mauna Kea. Simulation results for the Gemini project scheduler are presented in~\cite{puxley97}. The general observations plan description is similar to~\cite{silva02}, but with less institutional experience. This work focuses on how to distribute observing time in the future, based on ambient factors, but also the partners' proportion. Observable nights are divided into 6-months periods, and A and B types, depending on sky quality.

\subsection{Robert C. Byrd Green Bank Telescope (GBT)}
The GBT is the world's largest fully movable radio telescope antenna. It is located in West Virginia, and operated by the National Radio Astronomy Observatory (NRAO). A prototype automatic scheduling system has been recently introduced: the GBT Dynamic Scheduling System (DDS), described in~\cite{Oneil09}. Other than in other dynamic scheduling outlines, this telescope is very interactive and requires the presence of the observing astronomer. Therefore, the ``Dynamic Scheduling System is scheduling people rather than scripts'', and predictions are an important need, mainly achieved through weather forecasts and weather data from the last four years. The candidates determination for certain periods based on this data is described in~\cite{balser09}. The scoring algorithm in the GBT DDS assigns a priority number to each proposal, taking specially into account the weather predictions, but also stringency and observing efficiency. The actual scheduling algorithms are described by~\cite{Sessoms09}, in a 2-phase approach: Sudoku solver for fixed and windowed sessions, and Knapsack algorithm for optimal schedules of remaining time intervals. In conclusion, by dynamic scheduling it is possible to substantially improve telescope time usage efficiency.

\subsection{Low-Frequency Array}
The LOFAR radio-telescope was built and is operated by ASTRON, located in Netherlands. The telescope is based in small omni-directional antennas, which form a vast array. LOFAR observes the lowest region of the electromagnetic spectrum, between the 10-220 MHz, allowing to observe simultaneously multiple observations. The scheduling process described in~\cite{RJBHW2002} considers sharing of common resources, such as the antennas, meanwhile there are other resources that cannot be shared among the simultaneous observations.  The parallel scheduling problem formulation presented uses two abstractions: observation types (abstraction of execution modes) and virtual instruments (abstraction of resources necessary). In~\cite{RJBHW2002} the restrictions and the simplification of the problem are presented, introducing an evolutionary algorithm and concluding that this approach gives a good solution for the problem.

\subsection{Atacama Large Millimiter/SubMillimiter Array Dynamic Scheduling Algorithm}
\label{sec:alma-dsa}

ALMA's Dynamic Scheduling Algorithm (DSA) is the process where the Scheduling subsystem selects the next Scheduling Block (SB) to be executed by an array in the telescope, according to several criteria such as the current weather conditions, the state of the telescope's hardware, the observation time that the Executives have spent so far in an observing season, etc. The algorithm aims to select the ``best'' SB given the system conditions at the time when the algorithm is executed. The complete algorithm is described in \cite{avarias11} 

The algorithm is ``greedy'', in the sense that in every iteration, it assumes that all the array resources are allocated to the next selected SB. The algorithm doesn't try optimize the set of selected SBs as a function of time for long periods of time ---like an observing season--- using estimated values for future conditions. It just selects the optimal SB for the current conditions. The algorithm doesn't try to come up with an optimal program for array configurations. This is assumed to be given as input to the algorithm. This problem statement is directly derived from the science requirements.

The current algorithm is divided in two steps. A first selection step, where the entire pool of SBs is scanned to discard SBs that can't be executed at this time. The result of this step is a set of candidate SBs, which are then scored to select the best. The required selection criteria are based on:
\begin{itemize}
\item SBs which haven't been completed yet.
\item SBs belonging to Executives that still have enough time left.
\item SBs for which the weather is satisfactory for the entire observation.
\item SBs for which the current array configuration is appropriate.
\item SBs with sources visible and outside the Sun and Moon avoidance zones for the entire time of the observation.
\item SBs with required hardware available.
\end{itemize}

For each one of the SBs, that at the current time satisfy all these requirements, a score number is calculated to account for each one of the following qualities: science grade, degree of completion of project, target SNR/Execution Time/Time Limit, expected weather pattern and uv-coverage/Side Lobes/Hour Angle coverage.

The scoring numbers are combined in a weighted sum to compute the final score of the
candidate SBs.

\subsection{Most recent research}
In 2011 Mora studied the problem~\cite{mora11}. In his thesis is proposed a general purpose mathematical model of the problem, however the model does not aim to solve the specific ALMA scheduling problem.Data taken from ALMA is used to validate the proposed model, though.

For the development of the model proposed it is considered the instances for single and multiples-arrays at the same time, they are treated as different telescopes. The parameters are divided among static and dynamic. The most relevant dynamic parameters are: The on-line weather parameters and the Project and Scheduling Block future feasibility which depends if them whether are or are not completed.

The scheduling selection process establishes two different selection queues: A long-term queue is used to maintain the collection of Scheduling Blocks that are feasible to observe during a time frame, the selection of the feasible Scheduling Blocks is based in the static parameters; and a short-term observing queue based on fixed observation time slots of 30 minutes, the Scheduling Block selection is based on the dynamic parameters identified for the problem. Multiple short-term queues are maintained according to the common priority of the scheduled observations.

The proposed algorithm seeks to maximize the scientific value, aiming to complete most of the top priority projects, however how the algorithm calculates the science value of the scheduled observation is uncertain due no scientific analysis was done in the presentation of the algorithm. Also it is stated that the algorithm could seek to maximize the array's usage proportion, minimizing the array's idle time. Nonetheless, the objective functions are not optimized explicitly.

In~\cite{buchner2011dynamic} is introduced the problem of parallel observations on radio-telescope arrays, the work considers over-subscription, letting to the scheduler to decide which observations to exclude. The work considers dynamic array splitting, focused in a real world solution for the Square Kilometer Array (SKA), taking as input data coming from the Allen Telescope Array (ATA). The work describes a Genetic Algorithm as a meta-heuristic and its respective movements and mutations, trying to solve multiple scenarios, where observations in parallel (up to 4) are run in the same telescope.

The Genetic Algorithm is able to solve successfully the problem presented, accommodating the ``best'' heuristic to solve the current problem being solved and thus keeping the approach robust to changes in the characteristics of the problem. The author put emphasis that this could help to solve future problems in ALMA, SKA and other similar projects, where dynamic parallel sub-arrays are required.